cex.main = 0.8,
main = "Run Coefficient distribution under sharp null")
abline(v = run_ate, col = "darkgreen")
plot(density(run_sim), col = "red",
cex.axis = 0.5,
cex.lab = 0.8,
cex.main = 0.8,
main = "Run coefficient distribution under sharp null")
abline(v = run_ate, col = "darkgreen")
run_ci
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE)
options(knitr.table.format = "latex")
suppressMessages(library(knitr))
suppressMessages(library(kableExtra))
suppressMessages(library(tidyverse))
suppressMessages(library(AER))
suppressMessages(library(foreign)) # to read files stored in foreign formats
PO_0 <- c(2, 3, 5, 1, 0, 2)
PO_1 <- c(1, 0, 2, 3, 4, 5)
Complier <- c("Complier", "Complier", "Complier",
"Non-complier", "Non-complier", "Non-complier")
fake_data <- data.frame(Complier, PO_0, PO_1, stringsAsFactors = FALSE)
fake_data$ATE <- fake_data$PO_1 - fake_data$PO_0
fake_data$CACE <- fake_data$ATE*(fake_data$Complier == "Complier")
means <- round(mapply(mean, fake_data),2)
fake_data <- rbind(fake_data, means)
fake_data[is.na(fake_data$Complier),]$Complier <- "Average"
kable(fake_data, booktabs = TRUE)
rm(list = ls())
n_treat <- 1000
n_control <- 2000
vote_rate_treat <- 400/n_treat
vote_rate_control <- 700/n_control
fake_compliance_rate <- 500/n_treat
real_compliance_rate <- 250/n_treat
ITT <- vote_rate_treat - vote_rate_control
fake_CACE <- ITT/fake_compliance_rate
cat("Estimated CACE for overestimated compliers: ", fake_CACE)
real_CACE <- ITT/real_compliance_rate
cat("Estimated CACE for actual compliers: ", real_CACE)
rm(list = ls())
d <- read.dta("./data/Guan_Green_CPS_2006.dta") # stata file
str(d)
d[is.na(d$turnout),]$dormid
d2 <- d[d$dormid != 22061122,]
ITT <- mean(d2[d2$treat2==1,]$turnout) - mean(d2[d2$treat2==0,]$turnout)
cat("ITT using difference in group means is: ", round(ITT,3))
coefficients(lm(turnout ~ treat2, data = d2))
d2 %>%
group_by(dormid) %>%
summarize(students = n(),
turnout = mean(turnout),
contact = mean(contact),
treat2 = mean(treat2)) -> d_aggr
summary(d_aggr)
itt.f <- function(outcome, treatment, weight) {
po_treat <- sum(outcome*treatment*weight)/sum(treatment*weight)
po_control <- sum(outcome*(1-treatment)*weight)/sum((1-treatment)*weight)
return(po_treat-po_control)
}
ITT <- itt.f(d_aggr$turnout, d_aggr$treat2, d_aggr$students)
cat("ITT using aggregated dataset and custom function is: ", round(ITT, 3))
n_treat <- sum(d_aggr$treat2 == 1)
n_control <- sum(d_aggr$treat2 == 0)
pval.f <- function(outcome, treatment, weight, nc, nt) {
itt.est <- itt.f(outcome, treatment, weight)
randomize.f <- function(nc, nt) sample(c(rep(0,nc), rep(1,nt)))
distribution.under.sharp.null <- replicate(10000,
itt.f(outcome, randomize.f(nc, nt), weight))
plot(density(distribution.under.sharp.null),
col = "red",
xlim = c(-0.15,0.15),
cex.axis = 0.5,
cex.lab = 0.8,
cex.main = 0.8,
main = "Distribution under sharp null")
abline(v = itt.est, col = "darkgreen")
mean(itt.est < distribution.under.sharp.null)
}
PVAL <- pval.f(d_aggr$turnout, d_aggr$treat2, d_aggr$students, n_control, n_treat)
cat("Probability of the sharp null hypothesis to be true given our data is: ", PVAL)
compliance_rate <- mean(d2[d2$treat2==1,]$contact)
CACE <- ITT/compliance_rate
cat("CACE extimated by using means: ", round(CACE,3))
cace_fit <- ivreg(turnout ~ contact, ~treat2, data = d2)
coeftest(cace_fit, vcovHC(cace_fit))
rm(list=ls())
base_n <- 2572
treated_yes_n <- 486
treated_no_n <- 2086
placebo_yes_n <- 470
placebo_no_n <- 2109
base_turnout <- round(base_n*.3122)
treated_yes_turnout <- round(treated_yes_n*.3909)
treated_no_turnout <- round(treated_no_n*.3274)
placebo_yes_turnout <- round(placebo_yes_n*.2979)
placebo_no_turnout <- round(placebo_no_n*.3215)
reproduced_df <- data.frame("Group" = sample(c(rep(0, base_n),
rep(1, treated_yes_n),
rep(2, treated_no_n),
rep(3, placebo_yes_n),
rep(4, placebo_no_n))))
reproduced_df$TreatmentAssignment <- ifelse(reproduced_df$Group == 0, "Baseline",
ifelse(reproduced_df$Group < 3, "Treatment", "Placebo"))
reproduced_df$Treated <- ifelse(reproduced_df$Group %in% c(0,2,4) , 0, 1)
reproduced_df$Turnout <- 0
reproduced_df[reproduced_df$Group == 0,]$Turnout <-
sample(c(rep(0, base_n-base_turnout ), rep(1, base_turnout)))
reproduced_df[reproduced_df$Group == 1,]$Turnout <-
sample(c(rep(0, treated_yes_n-treated_yes_turnout ), rep(1, treated_yes_turnout)))
reproduced_df[reproduced_df$Group == 2,]$Turnout <-
sample(c(rep(0, treated_no_n-treated_no_turnout ), rep(1, treated_no_turnout)))
reproduced_df[reproduced_df$Group == 3,]$Turnout <-
sample(c(rep(0, placebo_yes_n-placebo_yes_turnout ), rep(1, placebo_yes_turnout)))
reproduced_df[reproduced_df$Group == 4,]$Turnout <-
sample(c(rep(0, placebo_no_n-placebo_no_turnout ), rep(1, placebo_no_turnout)))
reproduced_df %>%
group_by(Group, TreatmentAssignment, Treated) %>%
arrange(Group) %>%
summarize(N = n(),
Turnout_pct = round(100*mean(Turnout),2)) -> reproduced_summary
reproduced_summary$Group <- NULL
kable(reproduced_summary, booktabs = TRUE)
compl_rate_treat <-
mean(reproduced_df[reproduced_df$TreatmentAssignment=="Treatment",]$Treated)
compl_rate_placebo <-
mean(reproduced_df[reproduced_df$TreatmentAssignment=="Placebo",]$Treated)
cat("Compliance rate in the treatment group is :", compl_rate_treat)
cat("Compliance rate in the placebo group is :", compl_rate_placebo)
t.test(Treated ~ TreatmentAssignment, data = subset(reproduced_df, Group != 0))
t.test(Turnout ~ TreatmentAssignment, data = subset(reproduced_df, Group %in% c(2,4)))
itt_placebo <- mean(reproduced_df[reproduced_df$TreatmentAssignment=="Placebo",]$Turnout) -
mean(reproduced_df[reproduced_df$TreatmentAssignment=="Baseline",]$Turnout)
cace_placebo <- itt_placebo/compl_rate_placebo
cat("CACE of receiving placebo is: ", round(cace_placebo, 3))
cace_fit_placebo <- ivreg(Turnout ~ Treated, ~TreatmentAssignment,
data = subset(reproduced_df, TreatmentAssignment != "Treatment"))
coeftest(cace_fit_placebo, vcovHC(cace_fit_placebo))
itt_treat <- mean(reproduced_df[reproduced_df$TreatmentAssignment=="Treatment",]$Turnout) -
mean(reproduced_df[reproduced_df$TreatmentAssignment=="Baseline",]$Turnout)
cace_treat <- itt_treat/compl_rate_treat
cat("CACE of receiving treatment is: ", round(cace_treat, 3))
cace_fit_treat <- ivreg(Turnout ~ Treated, ~TreatmentAssignment,
data = subset(reproduced_df, TreatmentAssignment != "Placebo"))
coeftest(cace_fit_treat, vcovHC(cace_fit_treat))
reproduced_df %>%
filter(TreatmentAssignment != "Baseline" & Treated == 1) -> treated_df
t.test(Turnout ~ TreatmentAssignment, treated_df)
rm(list=ls())
d <- read.dta("./data/Hough_WorkingPaper_2010.dta")
summary(d)
tetris_ate <- mean(d[d$run==1,]$tetris, na.rm = TRUE)-mean(d[d$run==0,]$tetris, na.rm = TRUE)
cat("ATE of running on tetris score is: ", tetris_ate)
d$tetris_yesterday <- lag(d$tetris)
tetris_lag_lm <- lm(tetris_yesterday ~ run, data = d, na.omit = TRUE)
coeftest(tetris_lag_lm, vcovHC(tetris_lag_lm))
tetris_lm <- lm(tetris ~ run, data = d, na.omit = TRUE)
coeftest(tetris_lm, vcovHC(tetris_lm))
energy_lm <- lm(energy ~ run, data = d, na.omit = TRUE)
coeftest(energy_lm, vcovHC(energy_lm))
gre_lm <- lm(gre ~ run, data = d, na.omit = TRUE)
coeftest(gre_lm, vcovHC(gre_lm))
d$run_yesterday <- lag(d$run)
tetris_lm <- lm(tetris ~ run + run_yesterday, data = d, na.omit = TRUE)
coeftest(tetris_lm, vcovHC(tetris_lm))
run_se <- coeftest(tetris_lm, vcovHC(tetris_lm))["run","Std. Error"]
run_ci <- coefficients(tetris_lm)[2] + c(-1,1)*run_se*qt(0.975, df = 22)
cat("Confidence Interval for run is: ", run_ci)
lm.f <- function(depvar, indvar1, indvar2) {
lm_results <- lm(depvar ~ indvar1 + indvar2)
return(coefficients(lm_results)[2])
}
run_ate <- lm.f(d$tetris, d$run, d$run_yesterday)
lm_sim.f <- function(outcome, nc, nt) {
randomize.f <- function(nc, nt) sample(c(rep(0,nc), rep(1,nt)))
treatment <- randomize.f(nc, nt)
lm.f(outcome, treatment, lag(treatment))
}
run_day <- sum(d$run, na.rm = TRUE)
walk_day <- sum(1-d$run, na.rm = TRUE)
run_sim <- replicate(1000, lm_sim.f(d$tetris, walk_day, run_day))
plot(density(run_sim),
col = "red",
cex.axis = 0.5,
cex.lab = 0.8,
cex.main = 0.8,
main = "Run coefficient distribution under sharp null")
abline(v = run_ate, col = "darkgreen")
quantile(run_sim, prob = c(0.025, 0.975))
run_ci
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE)
options(knitr.table.format = "latex")
suppressMessages(library(knitr))
suppressMessages(library(kableExtra))
suppressMessages(library(tidyverse))
suppressMessages(library(AER))
suppressMessages(library(foreign)) # to read files stored in foreign formats
PO_0 <- c(2, 3, 5, 1, 0, 2)
PO_1 <- c(1, 0, 2, 3, 4, 5)
Complier <- c("Complier", "Complier", "Complier",
"Non-complier", "Non-complier", "Non-complier")
fake_data <- data.frame(Complier, PO_0, PO_1, stringsAsFactors = FALSE)
fake_data$ATE <- fake_data$PO_1 - fake_data$PO_0
fake_data$CACE <- fake_data$ATE*(fake_data$Complier == "Complier")
means <- round(mapply(mean, fake_data),2)
fake_data <- rbind(fake_data, means)
fake_data[is.na(fake_data$Complier),]$Complier <- "Average"
kable(fake_data, booktabs = TRUE)
rm(list = ls())
n_treat <- 1000
n_control <- 2000
vote_rate_treat <- 400/n_treat
vote_rate_control <- 700/n_control
fake_compliance_rate <- 500/n_treat
real_compliance_rate <- 250/n_treat
ITT <- vote_rate_treat - vote_rate_control
fake_CACE <- ITT/fake_compliance_rate
cat("Estimated CACE for overestimated compliers: ", fake_CACE)
real_CACE <- ITT/real_compliance_rate
cat("Estimated CACE for actual compliers: ", real_CACE)
rm(list = ls())
d <- read.dta("./data/Guan_Green_CPS_2006.dta") # stata file
str(d)
d[is.na(d$turnout),]$dormid
d2 <- d[d$dormid != 22061122,]
ITT <- mean(d2[d2$treat2==1,]$turnout) - mean(d2[d2$treat2==0,]$turnout)
cat("ITT using difference in group means is: ", round(ITT,3))
coefficients(lm(turnout ~ treat2, data = d2))
d2 %>%
group_by(dormid) %>%
summarize(students = n(),
turnout = mean(turnout),
contact = mean(contact),
treat2 = mean(treat2)) -> d_aggr
summary(d_aggr)
itt.f <- function(outcome, treatment, weight) {
po_treat <- sum(outcome*treatment*weight)/sum(treatment*weight)
po_control <- sum(outcome*(1-treatment)*weight)/sum((1-treatment)*weight)
return(po_treat-po_control)
}
ITT <- itt.f(d_aggr$turnout, d_aggr$treat2, d_aggr$students)
cat("ITT using aggregated dataset and custom function is: ", round(ITT, 3))
n_treat <- sum(d_aggr$treat2 == 1)
n_control <- sum(d_aggr$treat2 == 0)
pval.f <- function(outcome, treatment, weight, nc, nt) {
itt.est <- itt.f(outcome, treatment, weight)
randomize.f <- function(nc, nt) sample(c(rep(0,nc), rep(1,nt)))
distribution.under.sharp.null <- replicate(10000,
itt.f(outcome, randomize.f(nc, nt), weight))
plot(density(distribution.under.sharp.null),
col = "red",
xlim = c(-0.15,0.15),
cex.axis = 0.5,
cex.lab = 0.8,
cex.main = 0.8,
main = "Distribution under sharp null")
abline(v = itt.est, col = "darkgreen")
mean(itt.est < distribution.under.sharp.null)
}
PVAL <- pval.f(d_aggr$turnout, d_aggr$treat2, d_aggr$students, n_control, n_treat)
cat("Probability of the sharp null hypothesis to be true given our data is: ", PVAL)
compliance_rate <- mean(d2[d2$treat2==1,]$contact)
CACE <- ITT/compliance_rate
cat("CACE extimated by using means: ", round(CACE,3))
cace_fit <- ivreg(turnout ~ contact, ~treat2, data = d2)
coeftest(cace_fit, vcovHC(cace_fit))
rm(list=ls())
base_n <- 2572
treated_yes_n <- 486
treated_no_n <- 2086
placebo_yes_n <- 470
placebo_no_n <- 2109
base_turnout <- round(base_n*.3122)
treated_yes_turnout <- round(treated_yes_n*.3909)
treated_no_turnout <- round(treated_no_n*.3274)
placebo_yes_turnout <- round(placebo_yes_n*.2979)
placebo_no_turnout <- round(placebo_no_n*.3215)
reproduced_df <- data.frame("Group" = sample(c(rep(0, base_n),
rep(1, treated_yes_n),
rep(2, treated_no_n),
rep(3, placebo_yes_n),
rep(4, placebo_no_n))))
reproduced_df$TreatmentAssignment <- ifelse(reproduced_df$Group == 0, "Baseline",
ifelse(reproduced_df$Group < 3, "Treatment", "Placebo"))
reproduced_df$Treated <- ifelse(reproduced_df$Group %in% c(0,2,4) , 0, 1)
reproduced_df$Turnout <- 0
reproduced_df[reproduced_df$Group == 0,]$Turnout <-
sample(c(rep(0, base_n-base_turnout ), rep(1, base_turnout)))
reproduced_df[reproduced_df$Group == 1,]$Turnout <-
sample(c(rep(0, treated_yes_n-treated_yes_turnout ), rep(1, treated_yes_turnout)))
reproduced_df[reproduced_df$Group == 2,]$Turnout <-
sample(c(rep(0, treated_no_n-treated_no_turnout ), rep(1, treated_no_turnout)))
reproduced_df[reproduced_df$Group == 3,]$Turnout <-
sample(c(rep(0, placebo_yes_n-placebo_yes_turnout ), rep(1, placebo_yes_turnout)))
reproduced_df[reproduced_df$Group == 4,]$Turnout <-
sample(c(rep(0, placebo_no_n-placebo_no_turnout ), rep(1, placebo_no_turnout)))
reproduced_df %>%
group_by(Group, TreatmentAssignment, Treated) %>%
arrange(Group) %>%
summarize(N = n(),
Turnout_pct = round(100*mean(Turnout),2)) -> reproduced_summary
reproduced_summary$Group <- NULL
kable(reproduced_summary, booktabs = TRUE)
compl_rate_treat <-
mean(reproduced_df[reproduced_df$TreatmentAssignment=="Treatment",]$Treated)
compl_rate_placebo <-
mean(reproduced_df[reproduced_df$TreatmentAssignment=="Placebo",]$Treated)
cat("Compliance rate in the treatment group is :", compl_rate_treat)
cat("Compliance rate in the placebo group is :", compl_rate_placebo)
t.test(Treated ~ TreatmentAssignment, data = subset(reproduced_df, Group != 0))
t.test(Turnout ~ TreatmentAssignment, data = subset(reproduced_df, Group %in% c(2,4)))
itt_placebo <- mean(reproduced_df[reproduced_df$TreatmentAssignment=="Placebo",]$Turnout) -
mean(reproduced_df[reproduced_df$TreatmentAssignment=="Baseline",]$Turnout)
cace_placebo <- itt_placebo/compl_rate_placebo
cat("CACE of receiving placebo is: ", round(cace_placebo, 3))
cace_fit_placebo <- ivreg(Turnout ~ Treated, ~TreatmentAssignment,
data = subset(reproduced_df, TreatmentAssignment != "Treatment"))
coeftest(cace_fit_placebo, vcovHC(cace_fit_placebo))
itt_treat <- mean(reproduced_df[reproduced_df$TreatmentAssignment=="Treatment",]$Turnout) -
mean(reproduced_df[reproduced_df$TreatmentAssignment=="Baseline",]$Turnout)
cace_treat <- itt_treat/compl_rate_treat
cat("CACE of receiving treatment is: ", round(cace_treat, 3))
cace_fit_treat <- ivreg(Turnout ~ Treated, ~TreatmentAssignment,
data = subset(reproduced_df, TreatmentAssignment != "Placebo"))
coeftest(cace_fit_treat, vcovHC(cace_fit_treat))
reproduced_df %>%
filter(TreatmentAssignment != "Baseline" & Treated == 1) -> treated_df
t.test(Turnout ~ TreatmentAssignment, treated_df)
rm(list=ls())
d <- read.dta("./data/Hough_WorkingPaper_2010.dta")
summary(d)
tetris_ate <- mean(d[d$run==1,]$tetris, na.rm = TRUE)-mean(d[d$run==0,]$tetris, na.rm = TRUE)
cat("ATE of running on tetris score is: ", tetris_ate)
d$tetris_yesterday <- lag(d$tetris)
tetris_lag_lm <- lm(tetris_yesterday ~ run, data = d, na.omit = TRUE)
coeftest(tetris_lag_lm, vcovHC(tetris_lag_lm))
tetris_lm <- lm(tetris ~ run, data = d, na.omit = TRUE)
coeftest(tetris_lm, vcovHC(tetris_lm))
energy_lm <- lm(energy ~ run, data = d, na.omit = TRUE)
coeftest(energy_lm, vcovHC(energy_lm))
gre_lm <- lm(gre ~ run, data = d, na.omit = TRUE)
coeftest(gre_lm, vcovHC(gre_lm))
d$run_yesterday <- lag(d$run)
tetris_lm <- lm(tetris ~ run + run_yesterday, data = d, na.omit = TRUE)
coeftest(tetris_lm, vcovHC(tetris_lm))
run_se <- coeftest(tetris_lm, vcovHC(tetris_lm))["run","Std. Error"]
run_ci <- coefficients(tetris_lm)[2] + c(-1,1)*run_se*qt(0.975, df = 22)
cat("Confidence Interval for run is: ", run_ci)
lm.f <- function(depvar, indvar1, indvar2) {
lm_results <- lm(depvar ~ indvar1 + indvar2)
return(coefficients(lm_results)[2])
}
run_ate <- lm.f(d$tetris, d$run, d$run_yesterday)
lm_sim.f <- function(outcome, nc, nt) {
randomize.f <- function(nc, nt) sample(c(rep(0,nc), rep(1,nt)))
treatment <- randomize.f(nc, nt)
lm.f(outcome, treatment, lag(treatment))
}
run_day <- sum(d$run, na.rm = TRUE)
walk_day <- sum(1-d$run, na.rm = TRUE)
run_sim <- replicate(1000, lm_sim.f(d$tetris, walk_day, run_day))
plot(density(run_sim),
col = "red",
cex.axis = 0.5,
cex.lab = 0.8,
cex.main = 0.8,
main = "Run coefficient distribution under sharp null")
abline(v = run_ate, col = "darkgreen")
quantile(run_sim, prob = c(0.025, 0.975))
run_ci
rm(list = ls())
?lm
source('~/Documents/MIDS/W241/Group Project/sample_size_calculation.R', echo=TRUE)
source('~/Documents/MIDS/W241/Group Project/sample_size_calculation.R', echo=TRUE)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE)
options(knitr.table.format = "latex")
suppressMessages(library(knitr))
suppressMessages(library(kableExtra))
suppressMessages(library(tidyverse))
suppressMessages(library(AER))
suppressMessages(library(foreign)) # to read files stored in foreign formats
PO_0 <- c(2, 3, 5, 1, 0, 2)
PO_1 <- c(1, 0, 2, 3, 4, 5)
Complier <- c("Complier", "Complier", "Complier",
"Non-complier", "Non-complier", "Non-complier")
fake_data <- data.frame(Complier, PO_0, PO_1, stringsAsFactors = FALSE)
# fake_data$ATE <- fake_data$PO_1 - fake_data$PO_0
# fake_data$CACE <- fake_data$ATE*(fake_data$Complier == "Complier")
# means <- round(mapply(mean, fake_data),2)
# fake_data <- rbind(fake_data, means)
# fake_data[is.na(fake_data$Complier),]$Complier <- "Average"
cat("Table of potential outcomes to satisfy the assignment criteria:/n")
kable(fake_data, booktabs = TRUE)
fake_data$Complier=="Complier"
PO_0 <- c(2, 3, 5, 1, 0, 2)
PO_1 <- c(1, 0, 2, 3, 4, 5)
Complier <- c("Complier", "Complier", "Complier",
"Non-complier", "Non-complier", "Non-complier")
fake_data <- data.frame(Complier, PO_0, PO_1, stringsAsFactors = FALSE)
ATE <- mean(fake_data$PO_1 - fake_data$PO_0)
CACE <-  mean((fake_data$PO_1 - fake_data$PO_0)*fake_data$Complier=="Complier")
CACE <-  (fake_data$PO_1 - fake_data$PO_0)*fake_data$Complier=="Complier"
fake_data$PO_0*fake_data$Complier=="Complier"
fake_data$PO_0*(fake_data$Complier=="Complier")
CACE <- mean(fake_data[fake_data$Complier=="Complier",]$PO_1 - fake_data[fake_data$Complier=="Complier"]$PO_0)
fake_data[fake_data$Complier=="Complier",]$PO_1
fake_data[fake_data$Complier=="Complier"]$PO_0
CACE <- mean(fake_data[fake_data$Complier=="Complier",]$PO_1 - fake_data[fake_data$Complier=="Complier",]$PO_0)
PO_0 <- c(2, 3, 5, 1, 0, 2)
PO_1 <- c(1, 0, 2, 3, 4, 5)
Complier <- c("Complier", "Complier", "Complier",
"Non-complier", "Non-complier", "Non-complier")
fake_data <- data.frame(Complier, PO_0, PO_1, stringsAsFactors = FALSE)
fake_data$TE <- fake_data$PO_1 - fake_data$PO_0
ATE <- mean(fake_data$TE)
CACE <- mean(fake_data[fake_data$Complier=="Complier",]$TE)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE)
options(knitr.table.format = "latex")
suppressMessages(library(knitr))
suppressMessages(library(kableExtra))
suppressMessages(library(tidyverse))
suppressMessages(library(AER))
suppressMessages(library(foreign)) # to read files stored in foreign formats
PO_0 <- c(2, 3, 5, 1, 0, 2)
PO_1 <- c(1, 0, 2, 3, 4, 5)
Complier <- c("Complier", "Complier", "Complier",
"Non-complier", "Non-complier", "Non-complier")
fake_data <- data.frame(Complier, PO_0, PO_1, stringsAsFactors = FALSE)
fake_data$TE <- fake_data$PO_1 - fake_data$PO_0
ATE <- mean(fake_data$TE)
CACE <- mean(fake_data[fake_data$Complier=="Complier",]$TE)
cat("Table of potential outcomes to satisfy the assignment criteria:")
kable(fake_data, booktabs = TRUE)
cat("Based on the above data, ATE is:", ATE)
cat("ATE among compliers, or CACE, is:", CACE)
rm(list = ls())
n_treat <- 1000
n_control <- 2000
vote_rate_treat <- 400/n_treat
vote_rate_control <- 700/n_control
fake_compliance_rate <- 500/n_treat
real_compliance_rate <- 250/n_treat
ITT <- vote_rate_treat - vote_rate_control
fake_CACE <- ITT/fake_compliance_rate
cat("ITT is: ", ITT)
cat("Estimated CACE for overestimated compliers is: ", fake_CACE)
real_CACE <- ITT/real_compliance_rate
cat("Estimated CACE for actual compliers: ", real_CACE)
rm(list = ls())
d <- read.dta("./data/Guan_Green_CPS_2006.dta") # stata file
summary(d)
d[is.na(d$turnout),]$dormid
d2 <- d[d$dormid != 22061122,]
ITT <- mean(d2[d2$treat2==1,]$turnout) - mean(d2[d2$treat2==0,]$turnout)
cat("ITT using difference in group means is: ", round(ITT,3))
coefficients(lm(turnout ~ treat2, data = d2))
d2 %>%
group_by(dormid) %>%
summarize(students = n(),
turnout = mean(turnout),
contact = mean(contact),
treat2 = mean(treat2)) -> d_aggr
summary(d_aggr)
itt.f <- function(outcome, treatment, weight) {
po_treat <- sum(outcome*treatment*weight)/sum(treatment*weight)
po_control <- sum(outcome*(1-treatment)*weight)/sum((1-treatment)*weight)
return(po_treat-po_control)
}
ITT <- itt.f(d_aggr$turnout, d_aggr$treat2, d_aggr$students)
cat("Check: ITT using aggregated dataset and custom ITT function is: ", round(ITT, 3))
pval.f <- function(outcome, treatment, weight, nc, nt) {
itt.est <- itt.f(outcome, treatment, weight)
randomize.f <- function(nc, nt) sample(c(rep(0,nc), rep(1,nt)))
distribution.under.sharp.null <- replicate(10000,
itt.f(outcome, randomize.f(nc, nt), weight))
plot(density(distribution.under.sharp.null),
col = "red",
xlim = c(-0.15,0.15),
cex.axis = 0.5,
cex.lab = 0.8,
cex.main = 0.8,
main = "Distribution under sharp null")
abline(v = itt.est, col = "darkgreen")
mean(itt.est < distribution.under.sharp.null)
}
n_treat <- sum(d_aggr$treat2 == 1)
n_control <- sum(d_aggr$treat2 == 0)
PVAL <- pval.f(d_aggr$turnout, d_aggr$treat2, d_aggr$students, n_control, n_treat)
cat("Probability of seeing the data we have given that the sharp null is true is: ", PVAL)
compliance_rate <- mean(d2[d2$treat2==1,]$contact)
CACE <- ITT/compliance_rate
cat("CACE extimated by using means: ", round(CACE,3))
cace_fit <- ivreg(turnout ~ contact, ~treat2, data = d2)
coeftest(cace_fit, vcovHC(cace_fit))
lm(turnout ~ treat2, data = d2)
summary(lm(turnout ~ treat2, data = d2))
View(d2)
summary(d2)
d2 %>%
group_by(treat2, contact) %>%
summarize(turnout)
d2 %>%
group_by(treat2, contact) %>%
summarize(mean(turnout))
d2$leaflet <- d2$treat2 - d2$contact
sum(d2$leaflet)
d2$leaflet <- d2$treat2 - d2$contact
summary(lm(turnout ~ contact + leaflet, data=d2))
source('~/Documents/MIDS/W241/Group Project/Pilot results/quick_checks.R', echo=TRUE)
View(pilot)
